//
//  AnimeESRGANUpscaler.swift
//  NekoPicFixPro
//
//  æ’ç•«æ¨¡å¼ - é©åˆæ¼«ç•«ã€å‹•æ¼«ã€äºŒæ¬¡å…ƒ
//

import AppKit
import CoreML

/// Anime ESRGAN æ’ç•«æ¨¡å¼
/// é©åˆï¼šæ¼«ç•«ã€å‹•æ¼«ã€äºŒæ¬¡å…ƒã€éŠæˆ²æˆªåœ–ã€æ‰‹ç¹ªç·šç¨¿
class AnimeESRGANUpscaler: ImageUpscaler {

    // MARK: - Properties
    private let model: MLModel
    private let config: MLModelConfiguration
    private let inputName: String
    private let outputName: String

    // MARK: - Constants
    private let inputSize = 512
    private let outputSize = 2048
    private let maxInputDimension = 2048

    // MARK: - Errors
    enum UpscalerError: LocalizedError {
        case modelNotFound
        case conversionFailed
        case predictionFailed(String)
        case modelConfigurationError(String)

        var errorDescription: String? {
            switch self {
            case .modelNotFound:
                return "realesrganAnime512.mlmodel æœªæ‰¾åˆ°"
            case .conversionFailed:
                return "åœ–ç‰‡è½‰æ›å¤±æ•—"
            case .predictionFailed(let detail):
                return "æ¨¡å‹æ¨è«–å¤±æ•—: \(detail)"
            case .modelConfigurationError(let detail):
                return "æ¨¡å‹é…ç½®éŒ¯èª¤: \(detail)"
            }
        }
    }

    // MARK: - Initialization
    init() throws {
        config = MLModelConfiguration()
        config.computeUnits = .all

        print("ğŸ” è¼‰å…¥æ’ç•«æ¨¡å¼æ¨¡å‹...")

        // Try compiled model first
        if let compiledURL = Bundle.main.url(forResource: "realesrganAnime512", withExtension: "mlmodelc") {
            print("âœ… æ‰¾åˆ°å·²ç·¨è­¯æ¨¡å‹: realesrganAnime512.mlmodelc")
            model = try MLModel(contentsOf: compiledURL, configuration: config)
            print("âœ… æ’ç•«æ¨¡å¼æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        }
        // Fallback to .mlmodel
        else if let modelURL = Bundle.main.url(forResource: "realesrganAnime512", withExtension: "mlmodel") {
            print("âœ… æ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ: realesrganAnime512.mlmodel")
            let compiledURL = try MLModel.compileModel(at: modelURL)
            model = try MLModel(contentsOf: compiledURL, configuration: config)
            print("âœ… æ’ç•«æ¨¡å¼æ¨¡å‹ç·¨è­¯ä¸¦è¼‰å…¥æˆåŠŸ")
        } else {
            print("âŒ æ’ç•«æ¨¡å¼æ¨¡å‹æœªæ‰¾åˆ°")
            throw UpscalerError.modelNotFound
        }

        // Detect feature names
        let modelDescription = model.modelDescription
        guard let firstInput = modelDescription.inputDescriptionsByName.first?.key,
              let firstOutput = modelDescription.outputDescriptionsByName.first?.key else {
            throw UpscalerError.modelConfigurationError("ç„¡æ³•å–å¾—æ¨¡å‹è¼¸å…¥/è¼¸å‡ºç‰¹å¾µåç¨±")
        }

        inputName = firstInput
        outputName = firstOutput
        print("   è¼¸å…¥: '\(inputName)', è¼¸å‡º: '\(outputName)'")
    }

    // MARK: - ImageUpscaler Protocol
    func upscale(_ image: NSImage) throws -> NSImage {
        // è¨˜éŒ„åŸå§‹å°ºå¯¸
        let originalSize = image.size
        let targetSize = NSSize(
            width: originalSize.width * 4,
            height: originalSize.height * 4
        )

        let preprocessed = preprocessImage(image)

        guard let inputBuffer = preprocessed.toPixelBuffer(width: inputSize, height: inputSize) else {
            throw UpscalerError.conversionFailed
        }

        let outputBuffer = try predict(inputBuffer: inputBuffer)

        guard let resultImage = NSImage.from(pixelBuffer: outputBuffer) else {
            throw UpscalerError.conversionFailed
        }

        // èª¿æ•´è¼¸å‡ºå°ºå¯¸ä»¥ä¿æŒåŸå§‹å¯¬é«˜æ¯”ä¾‹ï¼ˆ4xï¼‰
        guard let finalImage = resultImage.resized(to: targetSize) else {
            throw UpscalerError.conversionFailed
        }

        return finalImage
    }

    // MARK: - Private Methods
    private func preprocessImage(_ image: NSImage) -> NSImage {
        let size = image.size
        let maxDimension = max(size.width, size.height)

        if maxDimension > CGFloat(maxInputDimension) {
            let scale = CGFloat(maxInputDimension) / maxDimension
            let newSize = NSSize(width: size.width * scale, height: size.height * scale)
            return image.resized(to: newSize) ?? image
        }

        return image
    }

    private func predict(inputBuffer: CVPixelBuffer) throws -> CVPixelBuffer {
        let inputFeature = try MLDictionaryFeatureProvider(dictionary: [
            inputName: MLFeatureValue(pixelBuffer: inputBuffer)
        ])

        let prediction = try model.prediction(from: inputFeature)

        guard let outputFeature = prediction.featureValue(for: outputName),
              let outputBuffer = outputFeature.imageBufferValue else {
            throw UpscalerError.predictionFailed("ç„¡æ³•å–å¾—è¼¸å‡º")
        }

        return outputBuffer
    }
}
