//
//  MMRealSRNetUpscaler.swift
//  NekoPicFixPro
//
//  è‡ªç„¶ä¿®å¾©ï¼ˆæŸ”ï¼‰- è‡ªç„¶ç…§ç‰‡ä¿®å¾©ï¼ˆè¼ƒæŸ”å’Œæ•ˆæœï¼‰
//

import AppKit
import CoreML

/// MMRealSRNet è‡ªç„¶ä¿®å¾©ï¼ˆæŸ”ï¼‰æ¨¡å¼
/// é©åˆï¼šè‡ªç„¶ç…§ç‰‡ä¿®å¾©ï¼Œæ•ˆæœè¼ƒæŸ”å’Œ
class MMRealSRNetUpscaler: ImageUpscaler {

    // MARK: - Properties
    private let model: MLModel
    private let config: MLModelConfiguration
    private let inputName: String
    private let outputName: String

    // MARK: - Constants
    private var inputSize: Int = 512  // Will be detected from model
    private var outputSize: Int = 2048  // Will be detected from model
    private let maxInputDimension = 2048

    // MARK: - Errors
    enum UpscalerError: LocalizedError {
        case modelNotFound
        case conversionFailed
        case predictionFailed(String)
        case modelConfigurationError(String)

        var errorDescription: String? {
            switch self {
            case .modelNotFound:
                return "MMRealSRNet.mlmodel æœªæ‰¾åˆ°"
            case .conversionFailed:
                return "åœ–ç‰‡è½‰æ›å¤±æ•—"
            case .predictionFailed(let detail):
                return "æ¨¡å‹æ¨è«–å¤±æ•—: \(detail)"
            case .modelConfigurationError(let detail):
                return "æ¨¡å‹é…ç½®éŒ¯èª¤: \(detail)"
            }
        }
    }

    // MARK: - Initialization
    init() throws {
        config = MLModelConfiguration()
        config.computeUnits = .all

        print("ğŸ” è¼‰å…¥è‡ªç„¶ä¿®å¾©ï¼ˆæŸ”ï¼‰æ¨¡å‹...")

        // Try compiled model first
        if let compiledURL = Bundle.main.url(forResource: "MMRealSRNet", withExtension: "mlmodelc") {
            print("âœ… æ‰¾åˆ°å·²ç·¨è­¯æ¨¡å‹: MMRealSRNet.mlmodelc")
            model = try MLModel(contentsOf: compiledURL, configuration: config)
            print("âœ… è‡ªç„¶ä¿®å¾©ï¼ˆæŸ”ï¼‰æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        }
        // Fallback to .mlmodel
        else if let modelURL = Bundle.main.url(forResource: "MMRealSRNet", withExtension: "mlmodel") {
            print("âœ… æ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ: MMRealSRNet.mlmodel")
            let compiledURL = try MLModel.compileModel(at: modelURL)
            model = try MLModel(contentsOf: compiledURL, configuration: config)
            print("âœ… è‡ªç„¶ä¿®å¾©ï¼ˆæŸ”ï¼‰æ¨¡å‹ç·¨è­¯ä¸¦è¼‰å…¥æˆåŠŸ")
        } else {
            print("âŒ è‡ªç„¶ä¿®å¾©ï¼ˆæŸ”ï¼‰æ¨¡å‹æœªæ‰¾åˆ°")
            throw UpscalerError.modelNotFound
        }

        // Detect feature names and sizes
        let modelDescription = model.modelDescription
        guard let firstInput = modelDescription.inputDescriptionsByName.first?.key,
              let firstOutput = modelDescription.outputDescriptionsByName.first?.key else {
            throw UpscalerError.modelConfigurationError("ç„¡æ³•å–å¾—æ¨¡å‹è¼¸å…¥/è¼¸å‡ºç‰¹å¾µåç¨±")
        }

        inputName = firstInput
        outputName = firstOutput

        // Detect input/output sizes from model
        if let inputDesc = modelDescription.inputDescriptionsByName[firstInput],
           let imageConstraint = inputDesc.imageConstraint {
            inputSize = Int(imageConstraint.pixelsWide)
            print("   æª¢æ¸¬åˆ°è¼¸å…¥å°ºå¯¸: \(inputSize)Ã—\(inputSize)")
        }

        if let outputDesc = modelDescription.outputDescriptionsByName[firstOutput],
           let imageConstraint = outputDesc.imageConstraint {
            outputSize = Int(imageConstraint.pixelsWide)
            print("   æª¢æ¸¬åˆ°è¼¸å‡ºå°ºå¯¸: \(outputSize)Ã—\(outputSize)")
        }

        print("   è¼¸å…¥: '\(inputName)', è¼¸å‡º: '\(outputName)'")
    }

    // MARK: - ImageUpscaler Protocol
    func upscale(_ image: NSImage) throws -> NSImage {
        // è¨˜éŒ„åŸå§‹å°ºå¯¸ä¸¦è¨ˆç®—æ”¾å¤§å€ç‡
        let originalSize = image.size
        let scale = Double(outputSize) / Double(inputSize)
        let targetSize = NSSize(
            width: originalSize.width * scale,
            height: originalSize.height * scale
        )

        let preprocessed = preprocessImage(image)

        guard let inputBuffer = preprocessed.toPixelBuffer(width: inputSize, height: inputSize) else {
            throw UpscalerError.conversionFailed
        }

        let outputBuffer = try predict(inputBuffer: inputBuffer)

        guard let resultImage = NSImage.from(pixelBuffer: outputBuffer) else {
            throw UpscalerError.conversionFailed
        }

        // èª¿æ•´è¼¸å‡ºå°ºå¯¸ä»¥ä¿æŒåŸå§‹å¯¬é«˜æ¯”ä¾‹ï¼ˆ4xï¼‰
        guard let finalImage = resultImage.resized(to: targetSize) else {
            throw UpscalerError.conversionFailed
        }

        return finalImage
    }

    // MARK: - Private Methods
    private func preprocessImage(_ image: NSImage) -> NSImage {
        let size = image.size
        let maxDimension = max(size.width, size.height)

        if maxDimension > CGFloat(maxInputDimension) {
            let scale = CGFloat(maxInputDimension) / maxDimension
            let newSize = NSSize(width: size.width * scale, height: size.height * scale)
            return image.resized(to: newSize) ?? image
        }

        return image
    }

    private func predict(inputBuffer: CVPixelBuffer) throws -> CVPixelBuffer {
        let inputFeature = try MLDictionaryFeatureProvider(dictionary: [
            inputName: MLFeatureValue(pixelBuffer: inputBuffer)
        ])

        let prediction = try model.prediction(from: inputFeature)

        guard let outputFeature = prediction.featureValue(for: outputName),
              let outputBuffer = outputFeature.imageBufferValue else {
            throw UpscalerError.predictionFailed("ç„¡æ³•å–å¾—è¼¸å‡º")
        }

        return outputBuffer
    }
}
